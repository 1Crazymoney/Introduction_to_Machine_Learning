%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% beamer %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% To run - pdflatex filename.tex
%      acroread filename.pdf
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[compress,oilve]{beamer}
\mode<presentation>

\usetheme[]{CambridgeUS}
% other themes: AnnArbor, Antibes, Bergen, Berkeley, Berlin, Boadilla, boxes, CambridgeUS, Copenhagen, Darmstadt, default, Dresden, Frankfurt, Goettingen,
% Hannover, Ilmenau, JuanLesPins, Luebeck, Madrid, Maloe, Marburg, Montpellier, PaloAlto, Pittsburg, Rochester, Singapore, Szeged, classic

\usecolortheme{beaver}
% color themes: albatross, beaver, beetle, crane, default, dolphin,  fly, lily, orchid, rose, seagull, seahorse, sidebartab, whale, wolverine

\usefonttheme{professionalfonts}
% font themes: default, professionalfonts, serif, structurebold, structureitalicserif, structuresmallcapsserif


\hypersetup{pdfpagemode=FullScreen} % makes your presentation go automatically to full screen

% define your own colors:
\definecolor{Red}{rgb}{1,0,0}
\definecolor{Blue}{rgb}{0,0,1}
\definecolor{Green}{rgb}{0,1,0}
\definecolor{magenta}{rgb}{1,0,.6}
\definecolor{lightblue}{rgb}{0,.5,1}
\definecolor{lightpurple}{rgb}{0.8, 0.6, 0.9}
\definecolor{gold}{rgb}{.6,.5,0}
\definecolor{orange}{rgb}{1,0.4,0}
\definecolor{hotpink}{rgb}{1,0,0.5}
\definecolor{newcolor2}{rgb}{.5,.3,.5}
\definecolor{newcolor}{rgb}{0,.3,1}
\definecolor{newcolor3}{rgb}{1,0,.35}
\definecolor{darkgreen1}{rgb}{0, .35, 0}
\definecolor{darkgreen}{rgb}{0, .6, 0}
\definecolor{darkred}{rgb}{.75,0,0}
\definecolor{skyblue}{HTML}{75bbfd}

\definecolor{olive}{cmyk}{0.64,0,0.95,0.4}
\definecolor{purpleish}{cmyk}{0.75,0.75,0,0}


% % Define a custom color
% \definecolor{backcolour}{rgb}{0.95,0.95,0.92}
% \definecolor{codegreen}{rgb}{0,0.6,0}

% \usepackage{listings}

% % Define a custom style
% \lstdefinestyle{myStyle}{
%     backgroundcolor=\color{backcolour},   
%     commentstyle=\color{codegreen},
%     basicstyle=\ttfamily\tinytosmallsize,
%     breakatwhitespace=false,         
%     breaklines=true,                 
%     keepspaces=true,                 
%     numbers=left,       
%     numbersep=5pt,                  
%     showspaces=false,                
%     showstringspaces=false,
%     showtabs=false,                  
%     tabsize=2,
% }

% % Use \lstset to make myStyle the global default
% \lstset{style=myStyle}
% color def
\usepackage{color}
\definecolor{darkred}{rgb}{0.6,0.0,0.0}
\definecolor{darkgreen}{rgb}{0,0.50,0}
\definecolor{lightblue}{rgb}{0.0,0.42,0.91}
\definecolor{orange}{rgb}{0.99,0.48,0.13}
\definecolor{grass}{rgb}{0.18,0.80,0.18}
\definecolor{pink}{rgb}{0.97,0.15,0.45}

% listings
\usepackage{listings}

% General Setting of listings
\lstset{
  aboveskip=1em,
  breaklines=true,
  abovecaptionskip=5pt,
  captionpos=b,
  escapeinside={\%*}{*)},
  frame=single,
  numbers=left,
  numbersep=15pt,
  numberstyle=\tiny,
}
% 0. Basic Color Theme
\lstdefinestyle{colored}{ %
  basicstyle=\ttfamily,
  backgroundcolor=\color{white},
  commentstyle=\color{green}\itshape,
  keywordstyle=\color{blue}\bfseries\itshape,
  stringstyle=\color{red},
}
% 1. General Python Keywords List
\lstdefinelanguage{PythonPlus}[]{Python}{
  morekeywords=[1]{,as,assert,nonlocal,with,yield,self,True,False,None,} % Python builtin
  morekeywords=[2]{,__init__,__add__,__mul__,__div__,__sub__,__call__,__getitem__,__setitem__,__eq__,__ne__,__nonzero__,__rmul__,__radd__,__repr__,__str__,__get__,__truediv__,__pow__,__name__,__future__,__all__,}, % magic methods
  morekeywords=[3]{,object,type,isinstance,copy,deepcopy,zip,enumerate,reversed,list,set,len,dict,tuple,range,xrange,append,execfile,real,imag,reduce,str,repr,}, % common functions
  morekeywords=[4]{,Exception,NameError,IndexError,SyntaxError,TypeError,ValueError,OverflowError,ZeroDivisionError,}, % errors
  morekeywords=[5]{,ode,fsolve,sqrt,exp,sin,cos,arctan,arctan2,arccos,pi, array,norm,solve,dot,arange,isscalar,max,sum,flatten,shape,reshape,find,any,all,abs,plot,linspace,legend,quad,polyval,polyfit,hstack,concatenate,vstack,column_stack,empty,zeros,ones,rand,vander,grid,pcolor,eig,eigs,eigvals,svd,qr,tan,det,logspace,roll,min,mean,cumsum,cumprod,diff,vectorize,lstsq,cla,eye,xlabel,ylabel,squeeze,}, % numpy / math
}
% 2. New Language based on Python
\lstdefinelanguage{PyBrIM}[]{PythonPlus}{
  emph={d,E,a,Fc28,Fy,Fu,D,des,supplier,Material,Rectangle,PyElmt},
}
% 3. Extended theme
\lstdefinestyle{colorEX}{
  basicstyle=\ttfamily,
  backgroundcolor=\color{white},
  commentstyle=\color{darkgreen}\slshape,
  keywordstyle=\color{blue}\bfseries\itshape,
  keywordstyle=[2]\color{blue}\bfseries,
  keywordstyle=[3]\color{grass},
  keywordstyle=[4]\color{red},
  keywordstyle=[5]\color{orange},
  stringstyle=\color{darkred},
  emphstyle=\color{pink}\underbar,
}
\lstset{style=colored}

% can also choose different themes for the "inside" and "outside"

% \usepackage{beamerinnertheme_______}
% inner themes include circles, default, inmargin, rectangles, rounded

% \usepackage{beamerouterthemesmoothbars}
% outer themes include default, infolines, miniframes, shadow, sidebar, smoothbars, smoothtree, split, tree


\useoutertheme[subsection=true, height=40pt]{smoothbars}

% to have the same footer on all slides
%\setbeamertemplate{footline}[text line]{STUFF HERE!}
\setbeamertemplate{footline}[text line]{} % makes the footer EMPTY
% include packages
%

%show the page numbers in footnote
%\addtobeamertemplate{navigation symbols}{}{%
%	\usebeamerfont{footline}%
%	\usebeamercolor[fg]{footline}%
%	\hspace{1em}%
%	\insertframenumber/\inserttotalframenumber
%}

\setbeamercolor{footline}{fg=purpleish}
\setbeamerfont{footline}{series=\bfseries}

%add color to curent subsection
\setbeamertemplate{section in head/foot}{\hfill\tikz\node[rectangle, fill=darkred, rounded corners=1pt,inner sep=1pt,] {\textcolor{white}{\insertsectionhead}};}
\setbeamertemplate{section in head/foot shaded}{\textcolor{darkred}{\hfill\insertsectionhead}}

% Remove bullet of subsections
\setbeamertemplate{headline}
{%
	\begin{beamercolorbox}{section in head/foot}
		\insertsectionnavigationhorizontal{\textwidth}{}{}
	\end{beamercolorbox}%
}


% modify headlline, specially headline size
\setbeamertemplate{headline}{%
	\leavevmode%
	\hbox{%
		\begin{beamercolorbox}[wd=\paperwidth,ht=3.5ex,dp=1.125ex]{palette quaternary}%
			\insertsectionnavigationhorizontal{\paperwidth}{}{\hskip0pt plus1filll}
		\end{beamercolorbox}%
	}
}

\setbeamertemplate{footline}{%
	\leavevmode%
	\hbox{\begin{beamercolorbox}[wd=.5\paperwidth,ht=2.5ex,dp=1.125ex,leftskip=.3cm plus1fill,rightskip=.3cm]{author in head/foot}%
			\usebeamerfont{author in head/foot}\insertshortauthor ~ \insertshortinstitute
		\end{beamercolorbox}%
		\begin{beamercolorbox}[wd=.5\paperwidth,ht=2.5ex,dp=1.125ex,leftskip=.3cm,rightskip=.3cm plus1fil]{title in head/foot}%
			\usebeamerfont{title in head/foot}\insertshorttitle\hfill\insertframenumber\,/\,\inserttotalframenumber
	\end{beamercolorbox}}%
	\vskip0pt%
}


%\setbeamertemplate{navigation symbols}{}

\title{Autoencoders}
\author{ML Instruction Team, Fall 2022}
\institute[]{CE Department \newline  Sharif University of Technology \newline \newline \newline
            Mahsa Yazdani\newline
            Arian Amani}
\date[\today]{}
%\titlegraphic{\includegraphics[scale=.35]{example-image}}



%Write \usepackage{etex} just after the \documentclass line (it should be the first loaded package).
\usepackage{etex}
\usepackage{subcaption}
\usepackage{caption}
\usepackage{multicol}
\usepackage{amsmath}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage[all,knot]{xy}
\xyoption{arc}
\usepackage{url}
\usepackage{multimedia}
\usepackage{hyperref}
\hypersetup{colorlinks,linkcolor=blue,citecolor=red,urlcolor=darkred}
\usepackage{multirow}
\usepackage[font={scriptsize}]{caption}
\usepackage{pgf}
\usepackage{fontspec}
\usepackage{svg}

% \usepackage{biblatex}
% \addbibresource{Refrences.bib}
% \AtBeginBibliography{\small}


%\setsansfont[Scale=MatchLowercase, BoldFont = * Bold, ItalicFont = * Italic]{Caladea}

%\usepackage{enumitem,xcolor}
%\newcommand{\labelitemi}{$\blacksquare$}
%\newcommand{\labelitemii}{$\diamond$}
%\newcommand{\labelitemiii}{$\square$}
%\newcommand{\labelitemiv}{$\ast$}
%\setbeamercolor*{item}{fg=red}

% abbreviation
% \newrobustcmd{\B}{\bfseries}

\usefonttheme{professionalfonts} 
\setbeamertemplate{itemize item}{\color{skyblue}$\blacksquare$}
\setbeamertemplate{itemize subitem}{\color{hotpink}$\blacktriangleright$}
\setbeamertemplate{itemize subsubitem}{\color{orange}$\bullet$}


\usepackage{anyfontsize}
\usepackage{t1enc}
\usepackage{tikz}
\usetikzlibrary{calc,trees,positioning,arrows,chains,shapes.geometric,decorations.pathreplacing,decorations.pathmorphing,shapes,matrix,shapes.symbols}



\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{assumption}[theorem]{Assumption}

\usepackage{xcolor}
\newcommand{\tc}[2]{
	\textcolor{#1}{#2}
}

%\usepackage{fontspec, unicode-math}
%\setmainfont[Scale=0.9]{Nimbus Roman No9 L}
%\setmonofont[Scale=0.9]{Monaco}
\setsansfont[Scale=1]{Times New Roman}

\newcommand{\vect}[1]{\boldsymbol{#1}}

\definecolor{strings}{rgb}{.624,.251,.259}
\definecolor{keywords}{rgb}{.224,.451,.686}
\definecolor{comment}{rgb}{.322,.451,.322}


%\usepackage{smartdiagram}
%\usesmartdiagramlibrary{additions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Title Page Info %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Begin Your Document %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\fontsize{9}{9}
\begin{frame}[noframenumbering, plain]
	\titlepage
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%######

\frame{\frametitle{The Power Of Unsupervised Learning}
\centering
\begin{itemize}
    \normalsize {
	\item Huge datasets compared to supervised learning (No need for labeling)
	\item Can find previously unknown patterns in data that are impossible with supervised learning
	}
\end{itemize}	
\begin{figure}
    \centering
    % \hspace{3cm}
    \includegraphics[width=0.9\columnwidth]{figs/unsupervised-learning.jpg}
    \caption{Types of Machine learning: Deep learning (supervised and\tc{keywords}{unsupervised learning})(Jones [2017]), \href{https://www.researchgate.net/figure/Types-of-Machine-learning-Deep-learning-supervised-and-unsupervised-learning-and_fig5_335569456}{Source}}
\end{figure}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%######

\frame{\frametitle{Applications of Autoencoders}
\centering
\vspace{-0.2cm}
\begin{itemize}
    \normalsize {
	\item Compression:
	    \begin{itemize}
	        \item AEs can compress our input into a lower dimensional vector and try to reconstruct the original input from that vector
	    \end{itemize}
	}
\end{itemize}	
\begin{figure}
    \centering
    % \vspace{-1cm}
    \includegraphics[width=12cm, height=5cm]{figs/Applications1.png}
    \caption{\href{https://www.jeremyjordan.me/variational-autoencoders/}{Source}}
\end{figure}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%######

\frame{\frametitle{Applications of Autoencoders}
\centering
\vspace{-0.2cm}
\begin{itemize}
    \normalsize {
	\item Dimensionality Reduction:
	    \begin{itemize}
	        \item AEs can perform dimensionality reduction
	    \end{itemize}
	}
\end{itemize}	
\begin{figure}
    \centering
    % \vspace{-1cm}
    \includegraphics[width=12cm, height=5cm]{figs/Applications2.png}
    \caption{\href{https://www.assemblyai.com/blog/introduction-to-variational-autoencoders-using-keras/}{Source}}
\end{figure}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%######

\frame{\frametitle{Applications of Autoencoders}
\centering
\vspace{-0.2cm}
\begin{itemize}
    \normalsize {
	\item Image coloring and noise reduction
	}
\end{itemize}	
\begin{figure}
    \centering
    % \vspace{-1cm}
    \includegraphics[width=12cm, height=5cm]{figs/Applications3.png}
    \caption{\href{https://towardsdatascience.com/convolutional-autoencoders-for-image-noise-reduction-32fce9fc1763}{Source}}
\end{figure}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%######

\frame{\frametitle{Applications of Autoencoders}
% \centering
\vspace{-0.6cm}
\begin{itemize}
    \normalsize {
	\item Super-Resolution
	}
\end{itemize}	
\begin{figure}
    \centering
    \vspace{-0.5cm}
    \includegraphics[width=11cm, height=5cm]{figs/Applications4.png}
    \caption{\href{https://towardsdatascience.com/improving-pewdiepies-camera-quality-with-autoencoders-583635de1cde}{Source}}
\end{figure}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{\frametitle{What is an Autoencoder?}
\vspace{-0.2cm}	

\begin{itemize}
    \normalsize{
	\item 
    An \tc{keywords}{autoencoder} is a type of artificial neural network, capable of learning a low dimensional representation of the input data (codings), without supervision (unlabeled training data - unsupervised learning)
	\item 
	Autoencoders take an input $X$ and try to predict $X$. We use a \tc{keywords}{bottleneck} layer with a smaller dimension compared to the input, to use as the coding.
    }
\end{itemize}	
\begin{figure}
    \centering
    \vspace{-0.1cm}
    \includegraphics[width=10cm, height=4cm]{figs/Autoencoder1.png}
    \caption{Schematic structure of an autoencoder with 3 fully connected hidden layers. The code (z) is the most internal layer, \href{https://en.wikipedia.org/wiki/Autoencoder}{Source}}
\end{figure}

	
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame{\frametitle{Autoencoders: Structure}
	
\begin{itemize}
	\item 
	Encoder:  compress input into a latent-space of usually smaller dimension.  $h = f(x)$


	\item 
	Decoder: reconstruct input from the latent space. $r = g(f(x))$ with $r$ as close to $x$ as possible

    \hyperlink{bad_ae}{
    \begin{figure}[htp]
    \vspace{1ex}%
    \centering
    \includegraphics[width=10cm]{Bad_AE}
    \end{figure}}
	
	
\end{itemize}	
	
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{\frametitle{Autoencoders: Applications}
	
\begin{itemize}
	\item 
	Autoencoders can 
	\begin{itemize}
		\item act as feature detectors
		\item be used for unsupervised pretraining of deep neural networks
	\end{itemize}

    \hyperlink{AE}{
    \begin{figure}[htp]
    \vspace{1ex}%
    \centering
    \includegraphics[width=8cm]{AE_application}
    \end{figure}}
	
	
\end{itemize}	
	
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{\frametitle{Autoencoders: Applications}
	
\begin{itemize}
	\item 
	Autoencoders can be used as generative models. (will be discussed more later in this chapter.) 

    
    \hyperlink{generated_by_VAE}{
    \begin{figure}[htp]
    \vspace{2ex}%
    \centering
    \includegraphics[width=8cm]{generated_by_VAE}
    \end{figure}}
	
	
\end{itemize}	
	
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{\frametitle{Autoencoders: Applications}
	
\begin{itemize}
	\item 
	Watermark removal

    
    \hyperlink{watermark_removal}{
    \begin{figure}[htp]
    \vspace{4ex}%
    \centering
    \includegraphics[width=10cm]{watermark_removal}
    \end{figure}}
	
	
\end{itemize}	
	
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{\frametitle{Autoencoders: Applications}
	
\begin{itemize}
	\item 
	Noise reduction

    
    \hyperlink{noise_reduction}{
    \begin{figure}[htp]
    \vspace{2ex}%
    \centering
    \includegraphics[width=8cm]{noise_reduction}
    \end{figure}}
	
	
\end{itemize}	
	
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{\frametitle{Stacked Autoencoders}
	
\begin{itemize}
	\item 
	Autoencoders can have multiple hidden layers. In this case they are called \textit{stacked autoencoders} (or \textit{deep autoencoders}).
	\item
	Adding more layers helps the autoencoder learn more complex codings. but be careful about {\color{red}overfitting}!

    

    \hyperlink{stacked_ae}{
    \begin{figure}[htp]
    \vspace{2ex}%
    \centering
    \includegraphics[width=8cm]{stacked_AE}
    \end{figure}}
	
	
\end{itemize}	
	
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{\frametitle{Autoencoders \& Images}

	
	\centering
    \vspace{30 pt}
    \textbf{\large{Are normal Autoencoders suitable for working with images?}}

    

    \hyperlink{ae_1}{
    \begin{figure}[htp]
    \vspace{2ex}%
    \centering
    \includegraphics[width=10cm]{AE}
    \end{figure}}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{\frametitle{Autoencoders \& Images}

\begin{itemize}	
    \item 
    Convolutional Autoencoders

    

    \hyperlink{cnn_ae}{
    \begin{figure}[htp]
    \vspace{2ex}%
    \centering
    \includegraphics[width=10cm]{cnn_autoencoder}
    \end{figure}}

\end{itemize}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{\frametitle{Denoising Autoencoders}

\begin{itemize}	
    \item 
    Another way to force the autoencoder to learn useful features is to add noise to its inputs.
    
    \item 
    Denoising autoencoders train to minimize the loss between $x$ and $g(f(x+w))$, where $w$ is random noise.
    
    \item 
    Denoising autoencoders, with Gaussian noise (left) or dropout (right):


    \hyperlink{AE}{
    \begin{figure}[htp]
    \vspace{1ex}%
    \centering
    \includegraphics[width=10cm]{denoising_autoencoders}
    \end{figure}}

\end{itemize}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{\frametitle{Denoising Autoencoders}

\begin{itemize}	
    \item 
    A few noisy images (with half the pixels turned off), and the images reconstructed by the dropout-based denoising autoencoder. Notice how the autoencoder guesses details that are actually not in the input, such as the top of the white shirt (bottom row, fourth image).

    \hyperlink{AE}{
    \begin{figure}[htp]
    \vspace{1ex}%
    \centering
    \includegraphics[width=10cm]{denoising_pics}
    \end{figure}}

\end{itemize}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{\frametitle{Denoising Autoencoders}

\begin{itemize}	
    \item 
    Intuitively, a denoising autoencoder learns a projection from a neighborhood of our training data back onto the training data.

    \hyperlink{denoising}{
    \begin{figure}[htp]
    \vspace{1ex}%
    \centering
    \includegraphics[width=10cm]{denoising}
    \end{figure}}

\end{itemize}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{\frametitle{Autoencoder Generative Models}

	
	\centering
    \vspace{25 pt}
    \textbf{\large{How can we generate {\color{hotpink}{NEW}} data with Autoencoders??}}
    \vspace{5 pt}
    \newline
    hint: Autoencoder learns the feature space!

    

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{\frametitle{Walking through an example}

\begin{itemize}	
    \item 
    We want to reconstruct some shapes.

    \hyperlink{vae}{
    \begin{figure}[htp]
    \vspace{1ex}%
    \centering
    \includegraphics[width=10cm]{vae_1}
    \end{figure}}

\end{itemize}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{\frametitle{Walking through an example}

\begin{itemize}	
    \item 
    Not all of the points in latent space have meaningful reconstructions.

    \hyperlink{vae}{
    \begin{figure}[htp]
    \vspace{1ex}%
    \centering
    \includegraphics[width=9cm]{vae_2_1}
    \end{figure}}

\end{itemize}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{\frametitle{Walking through an example}

\begin{itemize}	
    \item 
    What we want is something like the following picture. So that with sampling from the latent space, we can generate new shapes.

    \hyperlink{vae}{
    \begin{figure}[htp]
    \vspace{1ex}%
    \centering
    \includegraphics[width=9cm]{vae_3}
    \end{figure}}

\end{itemize}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{\frametitle{Variational Autoencoders}

\begin{itemize}	
    \item 
    instead of directly producing a coding for a given input, the encoder produces a mean coding μ and a standard deviation σ. The actual coding is then sampled randomly from a Gaussian distribution with mean μ and standard deviation σ

    \hyperlink{ae}{
    \begin{figure}[htp]
    \vspace{1ex}%
    \centering
    \includegraphics[width=8cm]{vae_arch}
    \end{figure}}

\end{itemize}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{\frametitle{Variational Autoencoders}

    
    \begin{figure}[htp]
    \centering
    \hyperlink{vae}{
    \includegraphics[width=9cm]{vae_6}}

    \vspace{1 pt}
    
    \hyperlink{vae}{
    \includegraphics[width=9cm]{vae_4_1}}
    \end{figure}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{\frametitle{Test}
	
	
\begin{itemize}
	\item One
	\begin{itemize}
		\item One
		\item Two
		\item Three
	\end{itemize}

	\item 
	For two-dimensional tensors, we have a corresponding sum with indices $(a, b)$ for $f$ and $(i-a, j-b)$ for $g$, respectively:
	$$
	(f * g)(i, j)=\sum_a \sum_b f(a, b) g(i-a, j-b)
	$$
	
	\item 
	
	It is given by,
	$$
	\left.w_{t+1}=w_t-\left(\alpha_t / \sqrt{\left(v_t\right.}\right)+e\right) *\left(\delta L / \delta w_t\right)
	$$
	where,
	$$
	v_t=\beta * v_t+(1-\beta) *\left(\delta L / \delta w_t\right)^2
	$$
\end{itemize}	
	
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame{\frametitle{Image References}
	
\begin{itemize}
    
    \item
    \hypertarget{ae_arch}{https://lilianweng.github.io/posts/2018-08-12-vae/}
    
    \item
    \hypertarget{bad_ae}{https://emkademy.medium.com/1-first-step-to-generative-deep-learning-with-autoencoders-22bd41e56d18}
    
    \item
    \hypertarget{AE}{Aurelien Geron. 2019. Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems (2nd. ed.). O'Reilly Media, Inc.}
    
    \item
    \hypertarget{generated_by_VAE}{https://github.com/wojciechmo/vae}
    
	\item 
	\hypertarget{watermark_removal}{https://ai.googleblog.com/2017/08/making-visible-watermarks-more-effective.html}
	
	\item
	\hypertarget{noise_reduction}{https://medium.com/@harishr2301/denoising-autoencoders-996e866e5cd0}
	
	\item 
	\hypertarget{stacked_ae}{
	https://subscription.packtpub.com/book/big-data-and-business-intelligence/9781787121089/4/ch04lvl1sec51/setting-up-stacked-autoencoders}
	
	\item
	\hypertarget{ae_1}{https://www.analyticsvidhya.com/blog/2021/01/auto-encoders-for-computer-vision-an-endless-world-of-possibilities/}
	
	\item
	\hypertarget{cnn_ae}{https://towardsdatascience.com/convolutional-autoencoders-for-image-noise-reduction-32fce9fc1763}
	
	\item
	\hypertarget{denoising}{https://ift6266h17.files.wordpress.com/2017/03/14\_autoencoders.pdf}
	
	\item
	\hypertarget{vae}{https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73}


	
	
\end{itemize}	
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{\frametitle{References}
	
\begin{itemize}
    
    \item
    Aurelien Geron. 2019. Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems (2nd. ed.). O'Reilly Media, Inc.
    
    \item
    https://www.cs.toronto.edu/~rgrosse/courses/csc321\_2017/slides/lec20.pdf
    
    \item
    https://www.math.purdue.edu/~buzzard/MA598-Spring2019/Lectures/Lec16\%20-\%20Autoencoders.pptx
    
    \item
    http://cs231n.stanford.edu/slides/2019/cs231n\_2019\_lecture11.pdf
    
	
\end{itemize}	
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frametitle{Final Notes}
\centering
\vspace{50 pt}
\textbf{Thank You!}
\vspace{50pt}

\textbf{Any Question?}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}