{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNx2ze3Cfuh5"
   },
   "source": [
    "<div dir=\"rtl\" align=\"center\">\n",
    "<font face=\"XB Zar\" size=5>\n",
    "    <font face=\"IranNastaliq\" size=5>\n",
    "      به نام خدا\n",
    "    </font>\n",
    "    <br>\n",
    "    <font size=3>\n",
    "      دانشگاه صنعتی شریف - دانشکده مهندسی کامپیوتر\n",
    "    </font>\n",
    "    <br>\n",
    "    <font color=blue size=5>\n",
    "      مقدمه‌ای بر یادگیری ماشین\n",
    "    </font>\n",
    "    <br>\n",
    "    <hr/>\n",
    "    <font color=red size=6>\n",
    "      فصل دوم: رگرسیون خطی\n",
    "    </font>\n",
    "    <br>\n",
    "      نویسندگان:‌ سید امیرمحمد عیسی زاده\n",
    "    <hr>\n",
    "<br>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIGyifOmnOYc"
   },
   "source": [
    "\n",
    "  <div dir=rtl id=\"dataset\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "      <font color=\"red\" size=5>\n",
    "        رگرسیون خطی از پایه\n",
    "      </font>\n",
    "      <hr />\n",
    "در این قسمت ما از یک دیتاست ساده برای تخمین میزان محصول دو میوه(سیب  و پرتقال) با توجه به پارامتر های دما، میزان بارش و رطوبت در چندین منطقه استفاده میکنیم.\n",
    "    <br>\n",
    "      به این منظور دیتاست ساده ای را میسازیم:\n",
    "    </font>\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use numpy to define our inputs and targets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset (temp, rainfall, humidity, apples, oranges)\n",
    "df = np.array([[73, 67, 43, 56, 70], \n",
    "                   [91, 88, 64, 81, 101], \n",
    "                   [87, 134, 58, 119, 133], \n",
    "                   [102, 43, 37, 22, 37], \n",
    "                   [69, 96, 70, 103, 119]], dtype='float32')\n",
    "\n",
    "# reigons which are used as indexes\n",
    "regions = [\"Semnan\", \"Golestan\", \"Gilan\", \"Ghazvin\", \"Mazandaran\"]\n",
    "\n",
    "columns = [\"Temp(F)\", \"Rainfall(mm)\", \"Humidity(%)\", \"Apples(ton)\", \"Oranges(ton)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  <div dir=rtl>\n",
    "    <font face=\"XB Zar\" size=4>\n",
    "برای نمایش دیتاست از کتابخانه pandas استفاده میکنیم:\n",
    "    </font>\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temp(F)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Apples(ton)</th>\n",
       "      <th>Oranges(ton)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Semnan</th>\n",
       "      <td>73.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Golestan</th>\n",
       "      <td>91.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gilan</th>\n",
       "      <td>87.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ghazvin</th>\n",
       "      <td>102.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mazandaran</th>\n",
       "      <td>69.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Temp(F)  Rainfall(mm)  Humidity(%)  Apples(ton)  Oranges(ton)\n",
       "Semnan         73.0          67.0         43.0         56.0          70.0\n",
       "Golestan       91.0          88.0         64.0         81.0         101.0\n",
       "Gilan          87.0         134.0         58.0        119.0         133.0\n",
       "Ghazvin       102.0          43.0         37.0         22.0          37.0\n",
       "Mazandaran     69.0          96.0         70.0        103.0         119.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe using variable columns as columns and regions as index\n",
    "df = pd.DataFrame(df, columns=columns, index=regions)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl id=\"dataset\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "در رگرسیون خطی، هر مقدار خروجی(ستون های سیب و پرتقال)، به صورت جمع وزن داری از ستون های ورودی به اضافه یک مقدار ثابت در نظر گرفته میشوند:\n",
    "      <br>\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
    "orange = w21 * temp + w22 * rainfall + w23 * humidity + b2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl id=\"dataset\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "که به این معناست که خروجی های ما یک تابع خطی یا یک صفحه از ورودی ها است:\n",
    "      <br>\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![linear-regression-graph](https://i.imgur.com/4DJ9f8X.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmZv9X3O0cxg"
   },
   "source": [
    "\n",
    "  <div dir=rtl id=\"columns\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "      <font color=\"red\" size=5>\n",
    "        مفهوم رگرسیون خطی\n",
    "      </font>\n",
    "      <hr />\n",
    "      آموزش مدل رگرسیون خطی، عملا همان پیدا کردن مقدار بهینه برای وزن ها(w11 و w12 و ... و w23 و b1 و b2) است. وزن های آموزش دیده شده، برای پیشبینی داده های جدید استفاده خواهند شد. برای بهتر کردن مدل، که همان پیدا کردن وزن های بهتر باشد، از optimizer استفاده میکنیم. optimizer مورد استفاده در این تمرین، gradient descent است.\n",
    "      <br>\n",
    "      دیتاست را به دو بخش X و Y قسمت میکنیم که X همان ورودی های ما و Y میزان بهره برداری از میوه ها یا همان خروجی ها هستند.\n",
    "  </font>\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :3].to_numpy()\n",
    "Y = df.iloc[:, 3:].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl id=\"dataset\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "برای کار کردن راحت تر با داده ها و استفاده از قابلیت های بیشتر از کتابخانه pytorch استفاده میکنیم: \n",
    "      <br>\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.from_numpy(X)\n",
    "Y = torch.from_numpy(Y)\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl id=\"dataset\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "حال باید به وزن ها و دو مقدار ثابت، مقدار اولیه بدهیم. روش های مختلفی برای این کار وجود دارند که ما از مقداردهی رندوم استفاده میکنیم:\n",
    "      <br>\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2006, -0.5150,  0.3728],\n",
      "        [ 0.6184,  0.2134,  1.3572]], requires_grad=True)\n",
      "tensor([ 0.0215, -1.1809], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Weights and biases\n",
    "w = torch.randn(2, 3, requires_grad=True)\n",
    "b = torch.randn(2, requires_grad=True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "execution": {
     "iopub.execute_input": "2022-09-08T17:23:58.094178Z",
     "iopub.status.busy": "2022-09-08T17:23:58.093871Z",
     "iopub.status.idle": "2022-09-08T17:23:58.223769Z",
     "shell.execute_reply": "2022-09-08T17:23:58.222728Z",
     "shell.execute_reply.started": "2022-09-08T17:23:58.094152Z"
    },
    "id": "FWaKYE6Zego-",
    "outputId": "33aced47-2337-49da-b453-5f17ef3e90d8"
   },
   "source": [
    "<div dir=rtl id=\"dataset\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "عملا فرم ماتریس خروجی(Y) به این فرم است:\n",
    "      <br>\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![matrix-mult](https://i.imgur.com/WGXLFvA.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl id=\"dataset\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "با توجه به شکل بالا، به راحتی میتوانیم مدل را تعریف کنیم:\n",
    "      <br>\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "execution": {
     "iopub.execute_input": "2022-09-08T17:23:58.225234Z",
     "iopub.status.busy": "2022-09-08T17:23:58.224941Z",
     "iopub.status.idle": "2022-09-08T17:23:58.274266Z",
     "shell.execute_reply": "2022-09-08T17:23:58.272846Z",
     "shell.execute_reply.started": "2022-09-08T17:23:58.225206Z"
    },
    "id": "Vxei2ek5egpB",
    "outputId": "d274b0d2-34d1-45d8-acba-764df39ded53"
   },
   "outputs": [],
   "source": [
    "# @ represent matrix multiplication in pytorch and .t transposes the matrix \n",
    "def lr_model(x):\n",
    "    return x @ w.t() + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl id=\"dataset\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "این مدل را روی داده های ورودی، که همان X و W و B هستند تست میکنیم:\n",
    "      <br>\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -3.8102, 116.6204],\n",
       "        [ -3.1855, 160.7342],\n",
       "        [-29.9141, 159.9316],\n",
       "        [ 12.1289, 121.2915],\n",
       "        [ -9.4808, 156.9785]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = lr_model(X)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-09-08T17:23:58.275887Z",
     "iopub.status.busy": "2022-09-08T17:23:58.275573Z",
     "iopub.status.idle": "2022-09-08T17:23:58.309198Z",
     "shell.execute_reply": "2022-09-08T17:23:58.308143Z",
     "shell.execute_reply.started": "2022-09-08T17:23:58.275853Z"
    },
    "id": "-rUt-7j7egpD",
    "outputId": "a4f8f030-0e66-4a95-92a5-79d01e0460d5"
   },
   "source": [
    "<div dir=rtl id=\"dataset\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "حال معیاری برای میزان خطای مدل، تعریف میکنیم.\n",
    "      <br>\n",
    "      ما از معیار MSE(mean squared error) استفاده میکنیم که اخلاف توان دو پیش بینی ها نسبت به مقدار واقعی خروجی ها است.\n",
    "      <br>\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE loss\n",
    "def mse_loss(pred, real):\n",
    "    diff = pred - real\n",
    "    return torch.sum(diff * diff) / diff.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl id=\"dataset\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "تابع sum تمامی عناصر آن تنسور را با هم جمع میکند.\n",
    "      در تابع mse_loss در ابتدا اختلاف ها را بین دو ماتریس پیدا میکنیم، سپس تمامی این اختلاف ها را با هم جمع میکنیم و در انتها تقسیم بر تعداد عناصر میکنیم.\n",
    "      <br>\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6060.3623, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = mse_loss(predictions, Y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl id=\"dataset\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "همانطور که از خود مقادیر عناصر پیش‌بینی شده واضح بود، اختلاف خیلی زیاد است. این اختلاف به این دلیل است که هیچ بهینه سازی‌ای در وزن ها انجام ندادیم و صرفا یک پیش بینی رندوم کردیم.\n",
    "در بخش Gradient Descent نحوه بروزرسانی وزن ها توضیح داده شده است.\n",
    "      <br>\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl id=\"dataset\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "      حال که مقدار خطا را بدست آوردیم و وزن ها و بایاس های فعلی را داریم، باید مقدار گرادیان را حساب کنیم.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl id=\"dataset\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "      این تابع برای بدست آوردن اتوماتیک گرادیان ها با توجه به وزن ها و بایاس های فعلی میباشد، این تابع در صورتی قابل استفاده است که فیلد requires_grad در وزن ها و بایاس ها برابر با True باشد که در پایتورچ مقدار default این فیلد، True است\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7u-9szEQ1UST"
   },
   "source": [
    "\n",
    "  <div dir=rtl id=\"preprocessing\">\n",
    "    <font face=\"XB Zar\" size=4>\n",
    "      <font color=\"red\" size=5>Gradient Descent</font>\n",
    "      <hr />\n",
    "      مقدار loss ما یک تابع درجه در از وزن ها و بایاس ها است. و وظیفه ما این است که آن را به کمترین مقدار خودش برسانیم.\n",
    "        اگر به شکل پایین دقت کنیم، و با توجه به حساب دیفرانسیل، یک نقطه را در نظر بگیرید. دو حالت برای این نقطه ممکن است:\n",
    "        <br>\n",
    "         شیب یا همان گرادیان مثبت باشد:\n",
    "        <br>\n",
    "        1) اگر مقدار کمی عقب برویم، مقدار تابع کمتر میشود.\n",
    "        <br>\n",
    "        2)  اگر مقدار کمی جلو برویم، مقدار تابع بیشتر میشود.\n",
    "        <br>\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![postive-gradient](https://i.imgur.com/WLzJ4xP.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl id=\"dataset\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "         گرادیان منفی باشد:\n",
    "      <br>\n",
    "      1) اگر مقدار کمی عقب برویم، مقدار تابع بیشتر میشود.\n",
    "      <br>\n",
    "      2) اگر مقدار کمی جلو برویم، مقدار تابع کمتر میشود.\n",
    "      <br>\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![negative=gradient](https://i.imgur.com/dvG2fxU.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl id=\"dataset\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "        بنابراین، در هر مرحله مقدار گرادیان را در عدد کوچکی ضرب میکنیم و وزن ها را از این مقدار کم میکنیم.\n",
    "      این مقدار کوچک همان learning rate است که یکی از مهم ترین hyperparameter های هر مدل ماشین لرنینگ است.\n",
    "      دو حالت نامطلوب برای learning rate محتمل است:\n",
    "      <br>\n",
    "      <ul>\n",
    "  <li>مقدار کوچک تر از حد مطلوب: در این صورت مدل دیر همگرا میشود و مراحل بیشتری نیاز است، چون در هر مرحله مقدار بسیار کمی تغییر میکند.</li>\n",
    "  <li>مقدار بیشتر از حد مطلوب: در این صورت مدل در نهایت با حالت مینیمم فاصله زیادی خواهد داشت.</li>\n",
    "</ul>\n",
    "      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"center\">\n",
    "<img src=\"gradient_descent.avif\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(w, b, lr=1e-5):\n",
    "    with torch.no_grad():\n",
    "        w -= w.grad * 1e-5\n",
    "        b -= b.grad * 1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl id=\"dataset\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "این تابع چندین نکته دارد که مختص به کار با pytorch است:\n",
    "      <ul>\n",
    "  <li>torch.no_grad: از این عبارت استفاده میکنیم تا به pytorch بفهمانیم که در حین تغییر مقدار وزن ها و بایاس ها نیازی به تغییر مقدار گرادیان ها نیست.</li>\n",
    "  <li>grad : تابع تعبیه شده در pytorch برای محاسبه گرادیان ها</li>\n",
    "  <li>zero: این تابع برای صفر کردن گرادیان ها استفاده میشود، در صورت عدم استفاده از این تابع، در مرحله های بعدی، مقادیر حساب شده با مقادیر فعلی جمع میشوند و نتیجه نامطلوبی به ما میدهد.</li>\n",
    "</ul>\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ElZ0H5Fg2yw"
   },
   "source": [
    "\n",
    "  <div dir=\"rtl\" id=\"intro\">\n",
    "    <font face=\"XB Zar\" size=4>\n",
    "      <font color=\"red\" size=5>\n",
    "        آموزش مدل\n",
    "      </font>\n",
    "      <hr />\n",
    "       حال که همه بخش های مدل را بررسی کردیم، نوبت آزمایش آن است.\n",
    "        یک بار تمامی مراحل را مرور میکنیم:\n",
    "        <ol>\n",
    "            <li>تولید پیش بینی با استفاده از وزن های فعلی</li>\n",
    "            <li>محاسبه مقدار loss</li>\n",
    "            <li>محاسبه گرادیان ها با توجه به وزن ها و بایاس ها</li>\n",
    "            <li>آپدیت کردن وزن ها و بایاس ها</li>\n",
    "            <li>صفر کردن مقدار گرادیان ها</li>\n",
    "        </ol>\n",
    "        <br>\n",
    "        این کار ها را در چندین مرحله(epoch) انجام میدهیم.\n",
    "        <br>\n",
    "        حال باید تابعی را تعریف کنیم که این مراحل را انجام دهد.\n",
    "       </font>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(n_epoches, lr):\n",
    "    losses = []\n",
    "    for i in range(n_epoches):\n",
    "        # generating the predictions \n",
    "        predictions = lr_model(X)\n",
    "        # calculating the loss\n",
    "        loss = mse_loss(predictions, Y)\n",
    "        # detach().numpy() is used for converting tensor to array(our array has one value) \n",
    "        losses.append(loss.detach().numpy())\n",
    "        # calculating gradients\n",
    "        loss.backward()\n",
    "        # updating weights and biases\n",
    "        gradient_descent(w, b, lr)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl id=\"dataset\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "         مدلمان را در 100 مرحله تست میکنیم و مقدار learning rate را  1e-5 میگذاریم.\n",
    "      <br>\n",
    "      همچنین loss ها را در هر مرحله ذخیره میکنیم.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "n_epoches = 100\n",
    "losses = train_model(n_epoches, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "  \n",
    "# x axis values\n",
    "x = [i for i in range(n_epoches)]\n",
    "# corresponding y axis values\n",
    "y = losses\n",
    "  \n",
    "# plotting the points \n",
    "plt.plot(x, y)\n",
    "  \n",
    "# naming the x axis\n",
    "plt.xlabel('number of epoches')\n",
    "# naming the y axis\n",
    "plt.ylabel('loss')\n",
    "  \n",
    "# function to show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl id=\"dataset\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "         همانطور که مشاهده میکنید، در ابتدا به مقدار زیادی از خطا کم میشود و رفته رفته اختلاف خطا ها در دو مرحله متوالی کمتر میشود تا در نهایت در همسایگی کوچکی از مینیمم، تغییر کند. هر چه learning rate را کمتر کنیم طول این همسایگی کمتر میشود.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   <div dir=\"rtl\" id=\"intro\">\n",
    "    <font face=\"XB Zar\" size=4>\n",
    "      <font color=\"red\" size=5>\n",
    "        رگرسیون خطی با استفاده از torch.nn\n",
    "      </font>\n",
    "       <br>\n",
    "      حال دیتاست داده شده را با استفاده از مدل آماده linear regression در pytorch یاد میگیریم.\n",
    "        <br>\n",
    "        از کتابخانه TensorDataset برای ساختن دیتاست train استفاده میکنیم.\n",
    "       </font>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 73.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.],\n",
       "         [102.,  43.,  37.],\n",
       "         [ 69.,  96.,  70.]]),\n",
       " tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.],\n",
       "         [ 22.,  37.],\n",
       "         [103., 119.]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define dataset\n",
    "train_ds = TensorDataset(X, Y)\n",
    "train_ds[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl id=\"dataset\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "         از DataLoader خود pytorch برای load کردن دیتا استفاده میکنیم. با این کتابخانه میتوانیم دیتای train را به چندین branch تقسیم کنیم و همچنین قابلیت هایی از جمله shuffle کردن دیتا و ... به ما میدهد.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loader\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl id=\"dataset\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "         حال از مدل آماده pytorch استفاده میکنیم.\n",
    "      در این حالت نیازی به تعریف وزن و بایاس نیست و خود این مدل این کار را میکند.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4124,  0.0241, -0.3418],\n",
      "        [-0.2332,  0.3364, -0.4434]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.5499, -0.3642], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = nn.Linear(3, 2)\n",
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl id=\"dataset\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "         برای تعریف loss function از کتابخانه nn.functional استفاده میکنیم.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import nn.functional\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "loss_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl id=\"dataset\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "         برای optimizer از کتابخانه torch.optim استفاده میکنیم.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl id=\"dataset\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "تابع model.parameters وزن ها و بایاس ها را برمیگرداند.\n",
    "      <br>\n",
    "      حال باید تابعی برای آموزش مدل بنویسیم، دقیقا همان مراحل قبلی را تکرار میکنیم.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
    "    \n",
    "    # Repeat for given number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Train with batches of data\n",
    "        for xb,yb in train_dl:\n",
    "            \n",
    "            # 1. Generate predictions\n",
    "            pred = model(xb)\n",
    "            \n",
    "            # 2. Calculate loss\n",
    "            loss = loss_fn(pred, yb)\n",
    "            \n",
    "            # 3. Compute gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # 4. Update parameters using gradients\n",
    "            opt.step()\n",
    "            \n",
    "            # 5. Reset the gradients to zero\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        # Print the progress\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 801.0750\n",
      "Epoch [20/100], Loss: 516.7050\n",
      "Epoch [30/100], Loss: 459.6240\n",
      "Epoch [40/100], Loss: 412.9379\n",
      "Epoch [50/100], Loss: 371.7442\n",
      "Epoch [60/100], Loss: 335.3192\n",
      "Epoch [70/100], Loss: 303.0954\n",
      "Epoch [80/100], Loss: 274.5740\n",
      "Epoch [90/100], Loss: 249.3158\n",
      "Epoch [100/100], Loss: 226.9340\n"
     ]
    }
   ],
   "source": [
    "fit(100, model, loss_fn, opt, train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   <div dir=\"rtl\" id=\"intro\">\n",
    "    <font face=\"XB Zar\" size=4>\n",
    "      <font color=\"red\" size=5>\n",
    "        torch.nn بر روی کشتی تایتانیک!!\n",
    "      </font>\n",
    "       <br>\n",
    "      حال دیتاست داده شده را با استفاده از مدل آماده linear regression در pytorch یاد میگیریم.\n",
    "        <br>\n",
    "        از کتابخانه TensorDataset برای ساختن دیتاست train استفاده میکنیم.\n",
    "       </font>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_training = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\n",
    "dataset_testing = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
